{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNUAE0Nb1mAFmQSwZz8UzvV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wLXNH9DV0BQ-"},"outputs":[],"source":["#backpropagation algo  with multilayer perceptron\n","\n","from math import exp\n","from random import seed\n","from random import random\n","\n","# intialize a network\n","\n","def initialize_network(n_inputs, n_hidden, n_outputs):\n","  network = list()\n","  hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n","  network.append(hidden_layer)\n","  output_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n","  network.append(output_layer)\n","  return network\n","\n","#\tCalculate neuron activation for an input\n","\n","def activate(weights, inputs):\n","  activation = weights[-1]\n","  for i in range(len(weights)-1):\n","    activation += weights[i] * inputs[i]\n","  return activation\n","\n","#\tTransfer neuron activation\n","\n","def transfer(activation):\n","  return 1.0 / (1.0 + exp(-activation))\n"]},{"cell_type":"code","source":["#\tForward propagate input to a network output\n","\n","def forward_propagate(network, row):\n","  inputs = row\n","  for layer in network:\n","    new_inputs = []\n","    for neuron in layer:\n","      activation = activate(neuron['weights'], inputs)\n","      neuron['output'] = transfer(activation)\n","      new_inputs.append(neuron['output'])\n","    inputs = new_inputs\n","  return inputs\n","\n","#\tCalculate the derivative of an neuron output\n","\n","def transfer_derivative(output):\n","  return output * (1.0 - output)\n"],"metadata":{"id":"d122DK_236xC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#\tBackpropagate error and store in neurons\n","\n","def backward_propagate_error(network, expected):\n","  for i in reversed(range(len(network))):\n","    layer = network[i]\n","    errors = list()\n","    if i != len(network)-1:\n","      for j in range(len(layer)):\n","        error = 0.0\n","        for neuron in network[i + 1]:\n","          error += (neuron['weights'][j] * neuron['delta'])\n","        errors.append(error)\n","    else:\n","      for j in range(len(layer)):\n","        neuron = layer[j]\n","        errors.append(neuron['output'] - expected[j])\n","    for j in range(len(layer)):\n","      neuron = layer[j]\n","      neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n","\n","#\tUpdate network weights with error\n","\n","def update_weights(network, row, l_rate):\n","  for i in range(len(network)):\n","    inputs = row[:-1]\n","    if i != 0:\n","      inputs = [neuron['output'] for neuron in network[i - 1]]\n","    for neuron in network[i]:\n","      for j in range(len(inputs)):\n","        neuron['weights'][j] -= l_rate * neuron['delta'] * inputs[j]\n","      neuron['weights'][-1] -= l_rate * neuron['delta']\n"],"metadata":{"id":"ziV-OjT_38Cx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train a network for a fixed number of epochs\n","\n","def train_network(network, train, l_rate, n_epoch, n_outputs):\n","  for epoch in range(n_epoch):\n","    sum_error = 0\n","    for row in train:\n","      outputs = forward_propagate(network, row)\n","      expected = [0 for i in range(n_outputs)]\n","      expected[row[-1]] = 1\n","      sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n","      backward_propagate_error(network, expected)\n","      update_weights(network, row, l_rate)\n","    print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n","\n","# Test training backprop algorithm\n","\n","seed(1)\n","dataset = [[2.7810836,2.550537003,0],\n","[1.465489372,2.362125076,0],\n","[3.396561688,4.400293529,0],\n","[1.38807019,1.850220317,0],\n","[3.06407232,3.005305973,0],\n","[7.627531214,2.759262235,1],\n","[5.332441248,2.088626775,1],\n","[6.922596716,1.77106367,1],\n","[8.675418651,-0.242068655,1],\n","[7.673756466,3.508563011,1]]\n","n_inputs = len(dataset[0]) - 1\n","n_outputs = len(set([row[-1] for row in dataset]))\n","network = initialize_network(n_inputs, 3, n_outputs)\n","train_network(network, dataset, 0.5, 20, n_outputs)\n","for layer in network:\n","  print(layer)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jp34xBaU6Q7r","executionInfo":{"status":"ok","timestamp":1712634233632,"user_tz":-330,"elapsed":3,"user":{"displayName":"MAYANK VARSHNEY1","userId":"04138498084654532840"}},"outputId":"862a07d8-e0f5-4387-c293-8edb47b2a820"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[">epoch=0, lrate=0.500, error=6.880\n",">epoch=1, lrate=0.500, error=5.740\n",">epoch=2, lrate=0.500, error=5.326\n",">epoch=3, lrate=0.500, error=5.338\n",">epoch=4, lrate=0.500, error=5.299\n",">epoch=5, lrate=0.500, error=5.136\n",">epoch=6, lrate=0.500, error=4.924\n",">epoch=7, lrate=0.500, error=4.692\n",">epoch=8, lrate=0.500, error=4.419\n",">epoch=9, lrate=0.500, error=4.112\n",">epoch=10, lrate=0.500, error=3.785\n",">epoch=11, lrate=0.500, error=3.456\n",">epoch=12, lrate=0.500, error=3.138\n",">epoch=13, lrate=0.500, error=2.838\n",">epoch=14, lrate=0.500, error=2.563\n",">epoch=15, lrate=0.500, error=2.313\n",">epoch=16, lrate=0.500, error=2.089\n",">epoch=17, lrate=0.500, error=1.889\n",">epoch=18, lrate=0.500, error=1.710\n",">epoch=19, lrate=0.500, error=1.552\n","[{'weights': [0.2663982735658251, 0.7860076057871438, 0.7603367533444867], 'output': 0.9961594902966306, 'delta': -0.00011266901222636104}, {'weights': [-1.3444878930508433, 1.6885018370791403, 0.8349736211832041], 'output': 0.03511528034723944, 'delta': 0.006779040920950208}, {'weights': [0.4596808434404679, 0.31501546269848935, -0.09200869875100279], 'output': 0.9891637726486936, 'delta': -0.0007412193027702495}]\n","[{'weights': [-0.7317965482405842, 2.3716621057165623, -0.5690560485083125, -0.03474552839897625], 'output': 0.23494719808744585, 'delta': 0.04223105688058156}, {'weights': [0.012081755868224752, -2.081990765790971, 0.9829316104189589, 0.2403293399044485], 'output': 0.7465450873393752, 'delta': -0.04795760307252465}]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"joTBoQ5n6RHB"},"execution_count":null,"outputs":[]}]}